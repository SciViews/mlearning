<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Supervised classification using linear discriminant analysis — mlLda • mlearning</title><!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png"><link rel="apple-touch-icon" type="image/png" sizes="152x152" href="../apple-touch-icon-152x152.png"><link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png"><link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png"><link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png"><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.1/css/all.min.css" integrity="sha256-PbSmjxuVAzJ6FPvNYsrXygfGhNJYyZ2GktDbkMBqQZg=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.1/css/v4-shims.min.css" integrity="sha256-A6jcAdwFD48VMjlI3GDxUd+eCQa7/KWy6G9oe/ovaPA=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/headroom.min.js" integrity="sha256-DJFC1kqIhelURkuza0AvYal5RxMtpzLjFhsnVIeuk+U=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><!-- svPkgdown --><script src="../script.js"></script><!-- themify icon --><link rel="stylesheet" href="../themify-icons.css?nocache=123"><!--<link rel="stylesheet" href="../style.css?nocache=123">--><!-- bootstrat v4.1.1, required CSS from more recent version --><link rel="stylesheet" href="../bootstrap.more.css?nocache=123"><link href="../style.css?nocache=123" rel="stylesheet"><!-- end of addition for svPkgdown --><meta property="og:title" content="Supervised classification using linear discriminant analysis — mlLda"><meta property="og:description" content="Unified (formula-based) interface version of the linear discriminant
analysis algorithm provided by MASS::lda()."><meta name="twitter:card" content="summary"><!-- Mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js" async integrity="sha256-nlrDrBTHxJJlDDX22AS33xYI1OJHnGMDhiYMSe2U0e0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/config/TeX-AMS-MML_HTMLorMML.js" async integrity="sha256-4zys9A4hMQmtq2EUL+JRoXc0NZi8jVJMzb8onewOaSQ=" crossorigin="anonymous"></script><!-- Global site tag (gtag.js) - Google Analytics --><!--<script async src="https://www.googletagmanager.com/gtag/js?id=UA-462421-8"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-462421-8');
</script>--></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <!-- preloader start -->
<div class="preloader">
  <img src="../preloader.gif" alt="loading..."></div>
<!-- preloader end -->

<div class="navbar navbar-default navbar-fixed-top bg-secondary" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <div class="navbar-brand-container">
       <div class="navbar-brand-logo">
         <a class="external-link navbar-brand" href="https://www.sciviews.org">
          <img src="../logo_full.png" alt="SciViews"></a>
       </div>
       <div class="navbar-brand-package">
      </div>
      </div>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <!-- start svPkgdown global site search with Google -->
      <form action="https://www.google.com/search" class="navbar-form navbar-right search-form-global">
        <div class="form-group has-search">
          <span class="fa fa-search form-control-feedback-global"></span>
          <input type="text" class="form-control-global search-form-input" name="q" id="q" placeholder="Search..." required><input type="hidden" name="sitesearch" value="https://www.sciviews.org"></div>
      </form>
      <!-- end svPkgdown global site search with Google -->
      <ul class="nav navbar-nav navbar-right"><li class="active nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
        <li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/SciViews/mlearning/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul><div class="navbar-title">
        <a class="navbar-brand" href="../index.html"><p class="h2">mlearning <small>v1.2.1</small></p></a>
      </div>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
  <div class="navbar-spacer bg-light">
  </div>
</div><!--/.navbar -->

    <div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Supervised classification using linear discriminant analysis</h1>
      <small class="dont-index">Source: <a href="https://github.com/SciViews/mlearning/blob/HEAD/R/ml_lda.R" class="external-link"><code>R/ml_lda.R</code></a></small>
      <div class="d-none name"><code>mlLda.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Unified (formula-based) interface version of the linear discriminant
analysis algorithm provided by <code><a href="https://rdrr.io/pkg/MASS/man/lda.html" class="external-link">MASS::lda()</a></code>.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">mlLda</span><span class="op">(</span><span class="va">train</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">ml_lda</span><span class="op">(</span><span class="va">train</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for formula</span></span>
<span><span class="fu">mlLda</span><span class="op">(</span><span class="va">formula</span>, <span class="va">data</span>, <span class="va">...</span>, <span class="va">subset</span>, <span class="va">na.action</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for default</span></span>
<span><span class="fu">mlLda</span><span class="op">(</span><span class="va">train</span>, <span class="va">response</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for mlLda</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span></span>
<span>  <span class="va">object</span>,</span>
<span>  <span class="va">newdata</span>,</span>
<span>  type <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"class"</span>, <span class="st">"membership"</span>, <span class="st">"both"</span>, <span class="st">"projection"</span><span class="op">)</span>,</span>
<span>  prior <span class="op">=</span> <span class="va">object</span><span class="op">$</span><span class="va">prior</span>,</span>
<span>  dimension <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  method <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"plug-in"</span>, <span class="st">"predictive"</span>, <span class="st">"debiased"</span>, <span class="st">"cv"</span><span class="op">)</span>,</span>
<span>  <span class="va">...</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>
    <dl><dt>train</dt>
<dd><p>a matrix or data frame with predictors.</p></dd>


<dt>...</dt>
<dd><p>further arguments passed to <code><a href="https://rdrr.io/pkg/MASS/man/lda.html" class="external-link">MASS::lda()</a></code> or its  <code><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict()</a></code>
method (see the corresponding help page).</p></dd>


<dt>formula</dt>
<dd><p>a formula with left term being the factor variable to predict
and the right term with the list of independent, predictive variables,
separated with a plus sign. If the data frame provided contains only the
dependent and independent variables, one can use the <code>class ~ .</code> short
version (that one is strongly encouraged). Variables with minus sign are
eliminated. Calculations on variables are possible according to usual
formula convention (possibly protected by using <code><a href="https://rdrr.io/r/base/AsIs.html" class="external-link">I()</a></code>).</p></dd>


<dt>data</dt>
<dd><p>a data.frame to use as a training set.</p></dd>


<dt>subset</dt>
<dd><p>index vector with the cases to define the training set in use
(this argument must be named, if provided).</p></dd>


<dt>na.action</dt>
<dd><p>function to specify the action to be taken if <code>NA</code>s are
found. For <code>ml_lda()</code> <code>na.fail</code> is used by default. The calculation is
stopped if there is any <code>NA</code> in the data. Another option is <code>na.omit</code>,
where cases with missing values on any required variable are dropped (this
argument must be named, if provided). For the <code><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict()</a></code> method, the
default, and most suitable option, is <code>na.exclude</code>. In that case, rows with
<code>NA</code>s in <code>newdata=</code> are excluded from prediction, but reinjected in the
final results so that the number of items is still the same (and in the
same order as <code>newdata=</code>).</p></dd>


<dt>response</dt>
<dd><p>a vector of factor for the classification.</p></dd>


<dt>object</dt>
<dd><p>an <strong>mlLda</strong> object</p></dd>


<dt>newdata</dt>
<dd><p>a new dataset with same conformation as the training set (same
variables, except may by the class for classification or dependent variable
for regression). Usually a test set, or a new dataset to be predicted.</p></dd>


<dt>type</dt>
<dd><p>the type of prediction to return. <code>"class"</code> by default, the
predicted classes. Other options are <code>"membership"</code> the membership (a
number between 0 and 1) to the different classes, or <code>"both"</code> to return
classes and memberships. The <code>type = "projection"</code> returns a projection
of the individuals in the plane represented by the <code>dimension= </code>
discriminant components.</p></dd>


<dt>prior</dt>
<dd><p>the prior probabilities of class membership. By default, the
prior are obtained from the object and, if they where not changed,
correspond to the proportions observed in the training set.</p></dd>


<dt>dimension</dt>
<dd><p>the number of the predictive space to use. If <code>NULL</code> (the
default) a reasonable value is used. If this is less than min(p, ng-1),
only the first <code>dimension</code> discriminant components are used (except for
<code>method = "predictive"</code>), and only those dimensions are returned in x.</p></dd>


<dt>method</dt>
<dd><p><code>"plug-in"</code>, <code>"predictive"</code>, <code>"debiased"</code>, or <code>"cv"</code>.
<code>"plug-in"</code> (default) the usual unbiased parameter estimates are used.
With <code>"predictive"</code>, the parameters are integrated out using a vague prior.
With <code>"debiased"</code>, an unbiased estimator of the log posterior probabilities
is used. With <code>"cv"</code>, cross-validation is used instead. If you specify
<code>method = "cv"</code> then <code><a href="mlearning.html">cvpredict()</a></code> is used and you cannot provide
<code>newdata=</code> in that case.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    

<p><code>ml_lda()</code>/<code>mlLda()</code> creates an <strong>mlLda</strong>, <strong>mlearning</strong> object
containing the classifier and a lot of additional metadata used by the
functions and methods you can apply to it like <code><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict()</a></code> or
<code><a href="mlearning.html">cvpredict()</a></code>. In case you want to program new functions or extract
specific components, inspect the "unclassed" object using <code><a href="https://rdrr.io/r/base/class.html" class="external-link">unclass()</a></code>.</p>
    </div>
    <div class="section level2">
    <h2 id="see-also">See also<a class="anchor" aria-label="anchor" href="#see-also"></a></h2>
    <div class="dont-index"><p><code><a href="mlearning.html">mlearning()</a></code>, <code><a href="mlearning.html">cvpredict()</a></code>, <code><a href="confusion.html">confusion()</a></code>, also <code><a href="https://rdrr.io/pkg/MASS/man/lda.html" class="external-link">MASS::lda()</a></code> that
actually does the classification.</p></div>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="co"># Prepare data: split into training set (2/3) and test set (1/3)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"iris"</span>, package <span class="op">=</span> <span class="st">"datasets"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">train</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">34</span>, <span class="fl">51</span><span class="op">:</span><span class="fl">83</span>, <span class="fl">101</span><span class="op">:</span><span class="fl">133</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">iris_train</span> <span class="op">&lt;-</span> <span class="va">iris</span><span class="op">[</span><span class="va">train</span>, <span class="op">]</span></span></span>
<span class="r-in"><span><span class="va">iris_test</span> <span class="op">&lt;-</span> <span class="va">iris</span><span class="op">[</span><span class="op">-</span><span class="va">train</span>, <span class="op">]</span></span></span>
<span class="r-in"><span><span class="co"># One case with missing data in train set, and another case in test set</span></span></span>
<span class="r-in"><span><span class="va">iris_train</span><span class="op">[</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="cn">NA</span></span></span>
<span class="r-in"><span><span class="va">iris_test</span><span class="op">[</span><span class="fl">25</span>, <span class="fl">2</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="cn">NA</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="va">iris_lda</span> <span class="op">&lt;-</span> <span class="fu">ml_lda</span><span class="op">(</span>data <span class="op">=</span> <span class="va">iris_train</span>, <span class="va">Species</span> <span class="op">~</span> <span class="va">.</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">iris_lda</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> A mlearning object of class mlLda (linear discriminant analysis):</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Call: mlLda.formula(formula = Species ~ ., data = iris_train)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Trained using 99 out of 100 cases:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>     setosa versicolor  virginica </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>         33         33         33 </span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">iris_lda</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> A mlearning object of class mlLda (linear discriminant analysis):</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Initial call: mlLda.formula(formula = Species ~ ., data = iris_train)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Call:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lda(sapply(train, as.numeric), grouping = response, .args. = ..1)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Prior probabilities of groups:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>     setosa versicolor  virginica </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.3333333  0.3333333  0.3333333 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Group means:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>            Sepal.Length Sepal.Width Petal.Length Petal.Width</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> setosa         5.048485    3.478788     1.478788   0.2454545</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> versicolor     6.027273    2.763636     4.284848   1.3303030</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> virginica      6.642424    2.951515     5.642424   2.0090909</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Coefficients of linear discriminants:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>                    LD1        LD2</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Sepal.Length  0.731861  0.9595049</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Sepal.Width   1.522827 -2.8735104</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Petal.Length -1.992262 -0.1425383</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Petal.Width  -3.021434 -1.5467486</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Proportion of trace:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>    LD1    LD2 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 0.9916 0.0084 </span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">iris_lda</span>, col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="response.html">response</a></span><span class="op">(</span><span class="va">iris_lda</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="co"># Prediction using a test set</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">iris_lda</span>, newdata <span class="op">=</span> <span class="va">iris_test</span><span class="op">)</span> <span class="co"># class (default type)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [1] setosa     setosa     setosa     setosa     setosa     setosa    </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [7] setosa     setosa     setosa     setosa     setosa     setosa    </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [13] setosa     setosa     setosa     setosa     virginica  versicolor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [19] versicolor versicolor versicolor versicolor versicolor versicolor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [25] &lt;NA&gt;       versicolor versicolor versicolor versicolor versicolor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [31] versicolor versicolor versicolor versicolor virginica  virginica </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [37] virginica  virginica  virginica  virginica  virginica  virginica </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [43] virginica  virginica  virginica  virginica  virginica  virginica </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [49] virginica  virginica </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Levels: setosa versicolor virginica</span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">iris_lda</span>, type <span class="op">=</span> <span class="st">"membership"</span><span class="op">)</span> <span class="co"># posterior probability</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span>              setosa   versicolor    virginica</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [1,] 1.000000e+00 9.524232e-17 5.937500e-36</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [2,] 1.000000e+00 1.758123e-18 6.393714e-38</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [3,] 1.000000e+00 6.513799e-16 2.394500e-34</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [4,] 1.000000e+00 2.346163e-21 1.932405e-41</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [5,] 1.000000e+00 7.169015e-20 9.796544e-39</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [6,] 1.000000e+00 9.874841e-18 2.894202e-36</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [7,] 1.000000e+00 4.123017e-19 1.318116e-38</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [8,] 1.000000e+00 9.594213e-15 6.039947e-33</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [9,] 1.000000e+00 7.873691e-18 2.097109e-37</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [10,] 1.000000e+00 2.609732e-22 7.255914e-43</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [11,] 1.000000e+00 8.320901e-18 1.364519e-36</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [12,] 1.000000e+00 1.211508e-17 2.805560e-37</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [13,] 1.000000e+00 9.536296e-19 1.465443e-38</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [14,] 1.000000e+00 6.860245e-28 1.426815e-50</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [15,] 1.000000e+00 7.475537e-26 1.520329e-46</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [16,] 1.000000e+00 4.785676e-23 2.483069e-43</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [17,] 1.000000e+00 9.802813e-20 2.845112e-39</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [18,] 1.000000e+00 4.605666e-21 5.968926e-41</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [19,] 1.000000e+00 4.062215e-21 1.190882e-40</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [20,] 1.000000e+00 1.516425e-18 4.852725e-38</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [21,] 1.000000e+00 3.056987e-19 4.751958e-38</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [22,] 1.000000e+00 1.648141e-23 2.642554e-44</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [23,] 1.000000e+00 1.336747e-13 1.268148e-30</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [24,] 1.000000e+00 2.003584e-15 3.819817e-33</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [25,] 1.000000e+00 2.046680e-15 4.351542e-34</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [26,] 1.000000e+00 5.142538e-16 6.111497e-34</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [27,] 1.000000e+00 2.391388e-20 2.579476e-40</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [28,] 1.000000e+00 2.042960e-20 1.273291e-40</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [29,] 1.000000e+00 4.233371e-16 1.789849e-34</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [30,] 1.000000e+00 1.249215e-15 4.594423e-34</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [31,] 1.000000e+00 7.854999e-18 8.037421e-37</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [32,] 1.000000e+00 7.493326e-26 3.966815e-47</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [33,] 1.000000e+00 5.492045e-27 1.165689e-48</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [34,] 6.728356e-18 9.999301e-01 6.988092e-05</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [35,] 5.384547e-19 9.993600e-01 6.399678e-04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [36,] 1.279003e-21 9.971466e-01 2.853444e-03</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [37,] 1.491199e-21 9.997082e-01 2.917717e-04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [38,] 1.949409e-22 9.971777e-01 2.822274e-03</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [39,] 2.197454e-21 9.980027e-01 1.997293e-03</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [40,] 2.857474e-21 9.849268e-01 1.507319e-02</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [41,] 2.377941e-13 9.999999e-01 1.271743e-07</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [42,] 3.751481e-19 9.999124e-01 8.756011e-05</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [43,] 8.944958e-20 9.993947e-01 6.053269e-04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [44,] 1.386835e-17 9.999987e-01 1.273302e-06</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [45,] 2.421474e-19 9.992724e-01 7.275660e-04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [46,] 1.510041e-17 9.999993e-01 7.449744e-07</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [47,] 2.233292e-22 9.938387e-01 6.161252e-03</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [48,] 9.070886e-14 9.999985e-01 1.464089e-06</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [49,] 5.217489e-17 9.999732e-01 2.680851e-05</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [50,] 1.674158e-22 9.719677e-01 2.803234e-02</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [51,] 3.173058e-15 9.999990e-01 9.944224e-07</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [52,] 9.041922e-27 9.790373e-01 2.096266e-02</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [53,] 9.465411e-17 9.999970e-01 3.045202e-06</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [54,] 8.632202e-27 2.075616e-01 7.924384e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [55,] 2.159399e-16 9.999935e-01 6.542439e-06</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [56,] 1.428380e-27 8.568276e-01 1.431724e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [57,] 8.472457e-21 9.995057e-01 4.942844e-04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [58,] 2.784802e-17 9.999829e-01 1.705453e-05</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [59,] 5.450336e-18 9.999472e-01 5.280245e-05</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [60,] 4.174183e-22 9.989487e-01 1.051274e-03</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [61,] 4.534883e-26 7.602933e-01 2.397067e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [62,] 3.385492e-22 9.926904e-01 7.309575e-03</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [63,] 1.921877e-11 1.000000e+00 1.449145e-08</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [64,] 6.151650e-17 9.999974e-01 2.647688e-06</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [65,] 5.418928e-15 9.999997e-01 2.885234e-07</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [66,] 6.125645e-16 9.999968e-01 3.179623e-06</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [67,] 3.260056e-50 5.375879e-09 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [68,] 1.534619e-36 9.609211e-04 9.990391e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [69,] 4.298766e-41 3.843125e-05 9.999616e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [70,] 1.120396e-36 8.624695e-04 9.991375e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [71,] 2.665504e-44 1.851447e-06 9.999981e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [72,] 5.691479e-47 9.683420e-07 9.999990e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [73,] 1.005543e-31 3.051764e-02 9.694824e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [74,] 2.170455e-40 1.677627e-04 9.998322e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [75,] 1.299923e-40 2.936646e-04 9.997063e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [76,] 6.144375e-45 2.105094e-07 9.999998e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [77,] 4.613890e-31 1.568862e-02 9.843114e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [78,] 3.058067e-36 2.171019e-03 9.978290e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [79,] 8.517422e-38 2.969936e-04 9.997030e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [80,] 2.876903e-39 2.085888e-04 9.997914e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [81,] 1.721481e-44 1.154274e-06 9.999988e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [82,] 4.614421e-39 3.104958e-05 9.999690e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [83,] 8.029333e-34 5.762455e-03 9.942375e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [84,] 1.047025e-42 1.368459e-06 9.999986e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [85,] 7.150283e-57 2.601747e-09 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [86,] 7.847879e-32 2.568989e-01 7.431011e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [87,] 1.710232e-41 9.095346e-06 9.999909e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [88,] 5.034775e-36 7.039438e-04 9.992961e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [89,] 1.297055e-47 1.520685e-06 9.999985e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [90,] 2.216946e-30 1.336448e-01 8.663552e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [91,] 5.328521e-38 8.627299e-05 9.999137e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [92,] 7.527919e-35 2.899037e-03 9.971010e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [93,] 7.099373e-29 2.331240e-01 7.668760e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [94,] 1.017544e-28 1.325438e-01 8.674562e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [95,] 2.315077e-42 1.492841e-05 9.999851e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [96,] 8.918840e-31 1.250327e-01 8.749673e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [97,] 2.927915e-40 2.443079e-04 9.997557e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [98,] 7.078517e-35 5.907724e-04 9.994092e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [99,] 4.036304e-44 3.685307e-06 9.999963e-01</span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">iris_lda</span>, type <span class="op">=</span> <span class="st">"both"</span><span class="op">)</span> <span class="co"># both class and membership in a list</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $class</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [1] setosa     setosa     setosa     setosa     setosa     setosa    </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [7] setosa     setosa     setosa     setosa     setosa     setosa    </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [13] setosa     setosa     setosa     setosa     setosa     setosa    </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [19] setosa     setosa     setosa     setosa     setosa     setosa    </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [25] setosa     setosa     setosa     setosa     setosa     setosa    </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [31] setosa     setosa     setosa     versicolor versicolor versicolor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [37] versicolor versicolor versicolor versicolor versicolor versicolor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [43] versicolor versicolor versicolor versicolor versicolor versicolor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [49] versicolor versicolor versicolor versicolor versicolor virginica </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [55] versicolor versicolor versicolor versicolor versicolor versicolor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [61] versicolor versicolor versicolor versicolor versicolor versicolor</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [67] virginica  virginica  virginica  virginica  virginica  virginica </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [73] virginica  virginica  virginica  virginica  virginica  virginica </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [79] virginica  virginica  virginica  virginica  virginica  virginica </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [85] virginica  virginica  virginica  virginica  virginica  virginica </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [91] virginica  virginica  virginica  virginica  virginica  virginica </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [97] virginica  virginica  virginica </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Levels: setosa versicolor virginica</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $membership</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>              setosa   versicolor    virginica</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [1,] 1.000000e+00 9.524232e-17 5.937500e-36</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [2,] 1.000000e+00 1.758123e-18 6.393714e-38</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [3,] 1.000000e+00 6.513799e-16 2.394500e-34</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [4,] 1.000000e+00 2.346163e-21 1.932405e-41</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [5,] 1.000000e+00 7.169015e-20 9.796544e-39</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [6,] 1.000000e+00 9.874841e-18 2.894202e-36</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [7,] 1.000000e+00 4.123017e-19 1.318116e-38</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [8,] 1.000000e+00 9.594213e-15 6.039947e-33</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [9,] 1.000000e+00 7.873691e-18 2.097109e-37</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [10,] 1.000000e+00 2.609732e-22 7.255914e-43</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [11,] 1.000000e+00 8.320901e-18 1.364519e-36</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [12,] 1.000000e+00 1.211508e-17 2.805560e-37</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [13,] 1.000000e+00 9.536296e-19 1.465443e-38</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [14,] 1.000000e+00 6.860245e-28 1.426815e-50</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [15,] 1.000000e+00 7.475537e-26 1.520329e-46</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [16,] 1.000000e+00 4.785676e-23 2.483069e-43</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [17,] 1.000000e+00 9.802813e-20 2.845112e-39</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [18,] 1.000000e+00 4.605666e-21 5.968926e-41</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [19,] 1.000000e+00 4.062215e-21 1.190882e-40</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [20,] 1.000000e+00 1.516425e-18 4.852725e-38</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [21,] 1.000000e+00 3.056987e-19 4.751958e-38</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [22,] 1.000000e+00 1.648141e-23 2.642554e-44</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [23,] 1.000000e+00 1.336747e-13 1.268148e-30</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [24,] 1.000000e+00 2.003584e-15 3.819817e-33</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [25,] 1.000000e+00 2.046680e-15 4.351542e-34</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [26,] 1.000000e+00 5.142538e-16 6.111497e-34</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [27,] 1.000000e+00 2.391388e-20 2.579476e-40</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [28,] 1.000000e+00 2.042960e-20 1.273291e-40</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [29,] 1.000000e+00 4.233371e-16 1.789849e-34</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [30,] 1.000000e+00 1.249215e-15 4.594423e-34</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [31,] 1.000000e+00 7.854999e-18 8.037421e-37</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [32,] 1.000000e+00 7.493326e-26 3.966815e-47</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [33,] 1.000000e+00 5.492045e-27 1.165689e-48</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [34,] 6.728356e-18 9.999301e-01 6.988092e-05</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [35,] 5.384547e-19 9.993600e-01 6.399678e-04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [36,] 1.279003e-21 9.971466e-01 2.853444e-03</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [37,] 1.491199e-21 9.997082e-01 2.917717e-04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [38,] 1.949409e-22 9.971777e-01 2.822274e-03</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [39,] 2.197454e-21 9.980027e-01 1.997293e-03</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [40,] 2.857474e-21 9.849268e-01 1.507319e-02</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [41,] 2.377941e-13 9.999999e-01 1.271743e-07</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [42,] 3.751481e-19 9.999124e-01 8.756011e-05</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [43,] 8.944958e-20 9.993947e-01 6.053269e-04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [44,] 1.386835e-17 9.999987e-01 1.273302e-06</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [45,] 2.421474e-19 9.992724e-01 7.275660e-04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [46,] 1.510041e-17 9.999993e-01 7.449744e-07</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [47,] 2.233292e-22 9.938387e-01 6.161252e-03</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [48,] 9.070886e-14 9.999985e-01 1.464089e-06</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [49,] 5.217489e-17 9.999732e-01 2.680851e-05</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [50,] 1.674158e-22 9.719677e-01 2.803234e-02</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [51,] 3.173058e-15 9.999990e-01 9.944224e-07</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [52,] 9.041922e-27 9.790373e-01 2.096266e-02</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [53,] 9.465411e-17 9.999970e-01 3.045202e-06</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [54,] 8.632202e-27 2.075616e-01 7.924384e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [55,] 2.159399e-16 9.999935e-01 6.542439e-06</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [56,] 1.428380e-27 8.568276e-01 1.431724e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [57,] 8.472457e-21 9.995057e-01 4.942844e-04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [58,] 2.784802e-17 9.999829e-01 1.705453e-05</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [59,] 5.450336e-18 9.999472e-01 5.280245e-05</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [60,] 4.174183e-22 9.989487e-01 1.051274e-03</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [61,] 4.534883e-26 7.602933e-01 2.397067e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [62,] 3.385492e-22 9.926904e-01 7.309575e-03</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [63,] 1.921877e-11 1.000000e+00 1.449145e-08</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [64,] 6.151650e-17 9.999974e-01 2.647688e-06</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [65,] 5.418928e-15 9.999997e-01 2.885234e-07</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [66,] 6.125645e-16 9.999968e-01 3.179623e-06</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [67,] 3.260056e-50 5.375879e-09 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [68,] 1.534619e-36 9.609211e-04 9.990391e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [69,] 4.298766e-41 3.843125e-05 9.999616e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [70,] 1.120396e-36 8.624695e-04 9.991375e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [71,] 2.665504e-44 1.851447e-06 9.999981e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [72,] 5.691479e-47 9.683420e-07 9.999990e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [73,] 1.005543e-31 3.051764e-02 9.694824e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [74,] 2.170455e-40 1.677627e-04 9.998322e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [75,] 1.299923e-40 2.936646e-04 9.997063e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [76,] 6.144375e-45 2.105094e-07 9.999998e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [77,] 4.613890e-31 1.568862e-02 9.843114e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [78,] 3.058067e-36 2.171019e-03 9.978290e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [79,] 8.517422e-38 2.969936e-04 9.997030e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [80,] 2.876903e-39 2.085888e-04 9.997914e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [81,] 1.721481e-44 1.154274e-06 9.999988e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [82,] 4.614421e-39 3.104958e-05 9.999690e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [83,] 8.029333e-34 5.762455e-03 9.942375e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [84,] 1.047025e-42 1.368459e-06 9.999986e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [85,] 7.150283e-57 2.601747e-09 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [86,] 7.847879e-32 2.568989e-01 7.431011e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [87,] 1.710232e-41 9.095346e-06 9.999909e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [88,] 5.034775e-36 7.039438e-04 9.992961e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [89,] 1.297055e-47 1.520685e-06 9.999985e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [90,] 2.216946e-30 1.336448e-01 8.663552e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [91,] 5.328521e-38 8.627299e-05 9.999137e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [92,] 7.527919e-35 2.899037e-03 9.971010e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [93,] 7.099373e-29 2.331240e-01 7.668760e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [94,] 1.017544e-28 1.325438e-01 8.674562e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [95,] 2.315077e-42 1.492841e-05 9.999851e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [96,] 8.918840e-31 1.250327e-01 8.749673e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [97,] 2.927915e-40 2.443079e-04 9.997557e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [98,] 7.078517e-35 5.907724e-04 9.994092e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [99,] 4.036304e-44 3.685307e-06 9.999963e-01</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span><span class="co"># Type projection</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">iris_lda</span>, type <span class="op">=</span> <span class="st">"projection"</span><span class="op">)</span> <span class="co"># Projection on the LD axes</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span>               LD1          LD2</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [1,]  6.9568849  1.101758773</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [2,]  7.3143043  0.349409550</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [3,]  6.6903832  0.512302451</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [4,]  7.9437673 -0.526396971</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [5,]  7.4913946 -1.356759342</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [6,]  7.0443141 -0.490171701</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [7,]  7.4399757  0.034051280</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [8,]  6.4386717  0.909357381</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [9,]  7.2120848  0.954828771</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [10,]  8.1895682 -0.444199891</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [11,]  7.0943773 -0.172103518</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [12,]  7.1858422  1.160483149</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [13,]  7.4175902  0.723492195</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [14,]  9.5368393 -0.879689584</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [15,]  8.8708188 -2.477155425</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [16,]  8.2882993 -1.299744040</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [17,]  7.5625273 -0.297770308</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [18,]  7.8608135 -0.626881984</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [19,]  7.8201493 -1.174077249</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [20,]  7.3342677  0.389345573</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [21,]  7.3657232 -1.041401073</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [22,]  8.4479276 -0.853183613</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [23,]  6.0559967 -0.075179432</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [24,]  6.4966988 -0.214864995</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [25,]  6.6316187  1.169201608</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [26,]  6.6364628 -0.289552269</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [27,]  7.7386306 -0.061398786</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [28,]  7.7855741  0.240206078</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [29,]  6.7166258  0.306648073</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [30,]  6.6375292  0.689949598</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [31,]  7.1284334  0.108503501</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [32,]  8.9544702 -1.630830155</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [33,]  9.2233941 -1.770750771</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [34,] -1.4018257  0.215542317</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [35,] -1.7446333 -0.486327810</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [36,] -2.3278902  0.223760356</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [37,] -2.1734350  1.616896012</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [38,] -2.4798042  0.744773004</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [39,] -2.2617801  0.300772664</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [40,] -2.3661324 -1.052811848</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [41,] -0.1592556  1.317643422</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [42,] -1.6500487  0.862722175</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [43,] -1.8867796  0.039219364</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [44,] -1.0936527  2.534490411</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [45,] -1.8174507 -0.348616687</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [46,] -1.0533572  2.848024067</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [47,] -2.5173487  0.214041057</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [48,] -0.3896479  0.045755570</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [49,] -1.1759882  0.257803374</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [50,] -2.6346875 -0.679229623</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [51,] -0.6375420  1.205114077</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [52,] -3.4138326  2.195281602</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [53,] -0.9921706  1.461747971</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [54,] -3.6146724 -1.472866304</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [55,] -0.9729048  0.755843737</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [56,] -3.6807031  1.372163670</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [57,] -2.0653447  0.810741819</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [58,] -1.1987424  0.713582680</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [59,] -1.4014570  0.449203926</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [60,] -2.3565549  1.158791673</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [61,] -3.4300580 -0.004393127</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [62,] -2.4942258 -0.008076640</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [63,]  0.3323463  1.482037583</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [64,] -1.0184132  1.667402349</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [65,] -0.5170437  1.836331036</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [66,] -0.8433763  0.924272004</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [67,] -7.6753629 -2.630185338</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [68,] -5.3490939 -0.329497936</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [69,] -6.1389227 -0.367575061</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [70,] -5.3725855 -0.341041849</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [71,] -6.6809564 -1.083699014</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [72,] -7.1675754  0.012400591</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [73,] -4.5126905 -0.223477557</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [74,] -6.0353078  0.518686233</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [75,] -6.0874244  1.163656598</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [76,] -6.7590661 -2.642937904</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [77,] -4.3775210 -1.249274587</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [78,] -5.3084297  0.217697329</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [79,] -5.5615762 -0.598411216</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [80,] -5.8297626  0.008832618</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [81,] -6.7075280 -1.390223284</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [82,] -5.7555896 -1.837757310</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [83,] -4.8747045 -0.422238089</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [84,] -6.3774971 -2.359385918</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [85,] -8.9054854  0.905644030</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [86,] -4.5563357  1.932111501</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [87,] -6.1865638 -1.415020182</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [88,] -5.2468744 -0.934917158</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [89,] -7.2960376  0.823474190</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [90,] -4.2825677  0.333437008</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [91,] -5.5763665 -1.584922469</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [92,] -5.0539672 -0.396555891</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [93,] -4.0042449 -0.035610691</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [94,] -3.9720918 -0.720517080</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [95,] -6.3581122 -0.421764910</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [96,] -4.3557936  0.516003560</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [97,] -6.0180954  0.775820547</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [98,] -5.0291597 -1.815373745</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [99,] -6.6602556 -0.576439772</span>
<span class="r-in"><span><span class="co"># Add test set items to the previous plot</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html" class="external-link">points</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">iris_lda</span>, newdata <span class="op">=</span> <span class="va">iris_test</span>, type <span class="op">=</span> <span class="st">"projection"</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>  col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">iris_lda</span>, newdata <span class="op">=</span> <span class="va">iris_test</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fl">1</span>, pch <span class="op">=</span> <span class="fl">19</span><span class="op">)</span></span></span>
<span class="r-plt img"><img src="mlLda-1.png" alt="" width="700" height="433"></span>
<span class="r-in"><span><span class="co"># predict() and confusion() should be used on a separate test set</span></span></span>
<span class="r-in"><span><span class="co"># for unbiased estimation (or using cross-validation, bootstrap, ...)</span></span></span>
<span class="r-in"><span><span class="co"># Wrong, cf. biased estimation (so-called, self-consistency)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="confusion.html">confusion</a></span><span class="op">(</span><span class="va">iris_lda</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 99 items classified with 98 true positives (error rate = 1%)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>                Predicted</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Actual          01 02 03 (sum) (FNR%)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   01 setosa     33  0  0    33      0</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   02 versicolor  0 32  1    33      3</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   03 virginica   0  0 33    33      0</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   (sum)         33 32 34    99      1</span>
<span class="r-in"><span><span class="co"># Estimation using a separate test set</span></span></span>
<span class="r-in"><span><span class="fu"><a href="confusion.html">confusion</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">iris_lda</span>, newdata <span class="op">=</span> <span class="va">iris_test</span><span class="op">)</span>, <span class="va">iris_test</span><span class="op">$</span><span class="va">Species</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 50 items classified with 47 true positives (error rate = 6%)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>                Predicted</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Actual          01 02 03 04 (sum) (FNR%)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   01 setosa     16  0  0  0    16      0</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   02 NA          0  0  0  0     0       </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   03 versicolor  0  1 15  1    17     12</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   04 virginica   0  0  1 16    17      6</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   (sum)         16  1 16 17    50      6</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Another dataset (binary predictor... not optimal for lda, just for test)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"HouseVotes84"</span>, package <span class="op">=</span> <span class="st">"mlbench"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">house_lda</span> <span class="op">&lt;-</span> <span class="fu">ml_lda</span><span class="op">(</span>data <span class="op">=</span> <span class="va">HouseVotes84</span>, na.action <span class="op">=</span> <span class="va">na.omit</span>, <span class="va">Class</span> <span class="op">~</span> <span class="va">.</span><span class="op">)</span></span></span>
<span class="r-wrn co"><span class="r-pr">#&gt;</span> <span class="warning">Warning: </span>force conversion from factor to numeric; may be not optimal or suitable</span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">house_lda</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> A mlearning object of class mlLda (linear discriminant analysis):</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Initial call: mlLda.formula(formula = Class ~ ., data = HouseVotes84, na.action = na.omit)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Call:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lda(sapply(train, as.numeric), grouping = response, .args. = ..1)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Prior probabilities of groups:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   democrat republican </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.5344828  0.4655172 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Group means:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>                  V1       V2       V3       V4       V5       V6       V7</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> democrat   1.588710 1.451613 1.854839 1.048387 1.201613 1.443548 1.766129</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> republican 1.212963 1.472222 1.157407 1.990741 1.953704 1.870370 1.268519</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>                  V8       V9      V10      V11      V12      V13      V14</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> democrat   1.830645 1.790323 1.532258 1.508065 1.129032 1.290323 1.346774</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> republican 1.148148 1.138889 1.574074 1.157407 1.851852 1.842593 1.981481</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>                 V15      V16</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> democrat   1.596774 1.943548</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> republican 1.111111 1.666667</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Coefficients of linear discriminants:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>             LD1</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> V1   0.05874608</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> V2  -0.13982178</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> V3  -0.78702772</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> V4   5.64762176</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> V5   0.12150873</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> V6  -0.08307307</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> V7   0.24825927</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> V8  -0.06528145</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> V9  -0.21114235</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> V10  0.25213648</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> V11 -0.70823602</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> V12  0.02863686</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> V13  0.23819274</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> V14 -0.07092076</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> V15  0.18474183</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> V16  0.37102658</span>
<span class="r-in"><span><span class="fu"><a href="confusion.html">confusion</a></span><span class="op">(</span><span class="va">house_lda</span><span class="op">)</span> <span class="co"># Self-consistency (biased metrics)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 232 items classified with 225 true positives (error rate = 3%)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>                Predicted</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Actual           01  02 (sum) (FNR%)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   01 democrat   118   6   124      5</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   02 republican   1 107   108      1</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   (sum)         119 113   232      3</span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="confusion.html">confusion</a></span><span class="op">(</span><span class="va">house_lda</span><span class="op">)</span>, error.col <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="co"># Without error column</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 232 items classified with 225 true positives (error rate = 3%)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>                Predicted</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Actual           01  02 (sum)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   01 democrat   118   6   124</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   02 republican   1 107   108</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   (sum)         119 113   232</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># More complex formulas</span></span></span>
<span class="r-in"><span><span class="co"># Exclude one or more variables</span></span></span>
<span class="r-in"><span><span class="va">iris_lda2</span> <span class="op">&lt;-</span> <span class="fu">ml_lda</span><span class="op">(</span>data <span class="op">=</span> <span class="va">iris</span>, <span class="va">Species</span> <span class="op">~</span> <span class="va">.</span> <span class="op">-</span> <span class="va">Sepal.Width</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">iris_lda2</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> A mlearning object of class mlLda (linear discriminant analysis):</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Initial call: mlLda.formula(formula = Species ~ . - Sepal.Width, data = iris)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Call:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lda(sapply(train, as.numeric), grouping = response, .args. = ..1)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Prior probabilities of groups:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>     setosa versicolor  virginica </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.3333333  0.3333333  0.3333333 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Group means:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>            Sepal.Length Petal.Length Petal.Width</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> setosa            5.006        1.462       0.246</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> versicolor        5.936        4.260       1.326</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> virginica         6.588        5.552       2.026</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Coefficients of linear discriminants:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>                    LD1       LD2</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Sepal.Length -1.539022  1.591246</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Petal.Length  2.719004 -2.619277</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Petal.Width   2.035445  4.719647</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Proportion of trace:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>    LD1    LD2 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 0.9936 0.0064 </span>
<span class="r-in"><span><span class="co"># With calculation</span></span></span>
<span class="r-in"><span><span class="va">iris_lda3</span> <span class="op">&lt;-</span> <span class="fu">ml_lda</span><span class="op">(</span>data <span class="op">=</span> <span class="va">iris</span>, <span class="va">Species</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="va">Petal.Length</span><span class="op">)</span> <span class="op">+</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="va">Petal.Width</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html" class="external-link">I</a></span><span class="op">(</span><span class="va">Petal.Length</span><span class="op">/</span><span class="va">Sepal.Length</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">iris_lda3</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> A mlearning object of class mlLda (linear discriminant analysis):</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Initial call: mlLda.formula(formula = Species ~ log(Petal.Length) + log(Petal.Width) +     I(Petal.Length/Sepal.Length), data = iris)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Call:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lda(sapply(train, as.numeric), grouping = response, .args. = ..1)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Prior probabilities of groups:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>     setosa versicolor  virginica </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.3333333  0.3333333  0.3333333 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Group means:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>            log(Petal.Length) log(Petal.Width) I(Petal.Length/Sepal.Length)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> setosa             0.3727587       -1.4846488                    0.2927557</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> versicolor         1.4429301        0.2709331                    0.7177285</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> virginica          1.7094260        0.6967478                    0.8437495</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Coefficients of linear discriminants:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>                                    LD1        LD2</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log(Petal.Length)             3.487170 -8.4773418</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> log(Petal.Width)              1.213501 -0.8427381</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> I(Petal.Length/Sepal.Length) 12.699248 24.1497766</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Proportion of trace:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>    LD1    LD2 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 0.9992 0.0008 </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Factor levels with missing items are allowed</span></span></span>
<span class="r-in"><span><span class="va">ir2</span> <span class="op">&lt;-</span> <span class="va">iris</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">51</span><span class="op">:</span><span class="fl">100</span><span class="op">)</span>, <span class="op">]</span> <span class="co"># No Iris versicolor in the training set</span></span></span>
<span class="r-in"><span><span class="va">iris_lda4</span> <span class="op">&lt;-</span> <span class="fu">ml_lda</span><span class="op">(</span>data <span class="op">=</span> <span class="va">ir2</span>, <span class="va">Species</span> <span class="op">~</span> <span class="va">.</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">iris_lda4</span><span class="op">)</span> <span class="co"># missing class</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> A mlearning object of class mlLda (linear discriminant analysis):</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Initial call: mlLda.formula(formula = Species ~ ., data = ir2)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Call:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lda(sapply(train, as.numeric), grouping = response, .args. = ..1)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Prior probabilities of groups:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>    setosa virginica </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>       0.5       0.5 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Group means:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>           Sepal.Length Sepal.Width Petal.Length Petal.Width</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> setosa           5.006       3.428        1.462       0.246</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> virginica        6.588       2.974        5.552       2.026</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Coefficients of linear discriminants:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>                     LD1</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Sepal.Length -1.1338828</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Sepal.Width  -0.8603685</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Petal.Length  2.6138926</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Petal.Width   2.6310427</span>
<span class="r-in"><span><span class="co"># Missing levels are reinjected in class or membership by predict()</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">iris_lda4</span>, type <span class="op">=</span> <span class="st">"both"</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $class</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [1] setosa    setosa    setosa    setosa    setosa    setosa    setosa   </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [8] setosa    setosa    setosa    setosa    setosa    setosa    setosa   </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [15] setosa    setosa    setosa    setosa    setosa    setosa    setosa   </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [22] setosa    setosa    setosa    setosa    setosa    setosa    setosa   </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [29] setosa    setosa    setosa    setosa    setosa    setosa    setosa   </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [36] setosa    setosa    setosa    setosa    setosa    setosa    setosa   </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [43] setosa    setosa    setosa    setosa    setosa    setosa    setosa   </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [50] setosa    virginica virginica virginica virginica virginica virginica</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [57] virginica virginica virginica virginica virginica virginica virginica</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [64] virginica virginica virginica virginica virginica virginica virginica</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [71] virginica virginica virginica virginica virginica virginica virginica</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [78] virginica virginica virginica virginica virginica virginica virginica</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [85] virginica virginica virginica virginica virginica virginica virginica</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [92] virginica virginica virginica virginica virginica virginica virginica</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [99] virginica virginica</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Levels: setosa versicolor virginica</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $membership</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>              setosa versicolor    virginica</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [1,] 1.000000e+00          0 7.512831e-46</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [2,] 1.000000e+00          0 7.276088e-42</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [3,] 1.000000e+00          0 4.053527e-43</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [4,] 1.000000e+00          0 9.767576e-39</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [5,] 1.000000e+00          0 1.100925e-45</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [6,] 1.000000e+00          0 4.725337e-42</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [7,] 1.000000e+00          0 2.717145e-40</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [8,] 1.000000e+00          0 4.696606e-43</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   [9,] 1.000000e+00          0 6.665430e-38</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [10,] 1.000000e+00          0 2.135333e-42</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [11,] 1.000000e+00          0 2.258299e-47</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [12,] 1.000000e+00          0 4.302480e-40</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [13,] 1.000000e+00          0 8.984619e-43</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [14,] 1.000000e+00          0 4.320000e-44</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [15,] 1.000000e+00          0 1.896091e-56</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [16,] 1.000000e+00          0 6.736143e-50</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [17,] 1.000000e+00          0 2.140622e-48</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [18,] 1.000000e+00          0 2.966078e-44</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [19,] 1.000000e+00          0 3.436672e-45</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [20,] 1.000000e+00          0 3.105104e-44</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [21,] 1.000000e+00          0 1.235400e-42</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [22,] 1.000000e+00          0 4.078324e-42</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [23,] 1.000000e+00          0 2.817007e-49</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [24,] 1.000000e+00          0 2.930308e-35</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [25,] 1.000000e+00          0 2.463987e-35</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [26,] 1.000000e+00          0 2.217500e-39</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [27,] 1.000000e+00          0 2.821729e-38</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [28,] 1.000000e+00          0 5.940132e-45</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [29,] 1.000000e+00          0 5.126836e-46</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [30,] 1.000000e+00          0 2.321415e-38</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [31,] 1.000000e+00          0 1.584158e-38</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [32,] 1.000000e+00          0 1.296042e-42</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [33,] 1.000000e+00          0 1.109833e-49</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [34,] 1.000000e+00          0 2.949136e-52</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [35,] 1.000000e+00          0 8.430330e-41</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [36,] 1.000000e+00          0 9.076484e-47</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [37,] 1.000000e+00          0 3.450702e-50</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [38,] 1.000000e+00          0 1.359439e-46</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [39,] 1.000000e+00          0 5.197906e-40</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [40,] 1.000000e+00          0 9.633928e-44</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [41,] 1.000000e+00          0 3.751372e-45</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [42,] 1.000000e+00          0 1.898509e-35</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [43,] 1.000000e+00          0 4.696510e-41</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [44,] 1.000000e+00          0 1.322046e-35</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [45,] 1.000000e+00          0 2.706126e-36</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [46,] 1.000000e+00          0 1.400418e-39</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [47,] 1.000000e+00          0 3.031589e-44</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [48,] 1.000000e+00          0 7.617054e-41</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [49,] 1.000000e+00          0 1.100936e-46</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [50,] 1.000000e+00          0 4.053568e-44</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [51,] 4.617725e-58          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [52,] 8.798280e-41          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [53,] 3.746998e-46          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [54,] 1.244135e-42          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [55,] 2.725168e-50          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [56,] 8.161589e-54          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [57,] 2.612854e-35          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [58,] 7.462125e-47          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [59,] 3.861338e-45          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [60,] 6.860587e-52          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [61,] 5.943151e-35          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [62,] 7.949426e-40          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [63,] 7.138946e-42          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [64,] 1.592055e-42          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [65,] 3.051613e-48          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [66,] 1.333376e-43          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [67,] 3.791655e-39          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [68,] 3.922977e-52          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [69,] 3.638913e-63          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [70,] 4.805245e-34          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [71,] 1.663273e-46          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [72,] 4.634792e-40          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [73,] 3.682206e-54          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [74,] 1.421107e-32          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [75,] 3.628997e-44          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [76,] 3.227610e-41          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [77,] 3.738057e-31          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [78,] 2.201634e-32          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [79,] 2.962680e-47          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [80,] 6.753553e-36          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [81,] 4.115135e-45          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [82,] 8.322520e-43          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [83,] 7.504224e-49          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [84,] 1.958141e-30          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [85,] 3.454159e-39          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [86,] 2.172019e-48          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [87,] 1.338833e-49          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [88,] 2.587466e-39          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [89,] 1.740755e-31          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [90,] 4.462874e-39          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [91,] 2.053855e-48          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [92,] 1.639745e-37          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [93,] 8.798280e-41          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [94,] 2.296341e-50          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [95,] 1.493725e-50          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [96,] 5.380405e-41          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [97,] 8.437651e-37          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [98,] 1.393126e-37          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [99,] 1.610909e-45          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [100,] 6.235010e-37          0 1.000000e+00</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span><span class="co"># ... but, of course, the classifier is wrong for Iris versicolor</span></span></span>
<span class="r-in"><span><span class="fu"><a href="confusion.html">confusion</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">iris_lda4</span>, newdata <span class="op">=</span> <span class="va">iris</span><span class="op">)</span>, <span class="va">iris</span><span class="op">$</span><span class="va">Species</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 150 items classified with 100 true positives (error rate = 33.3%)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>                Predicted</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Actual           01  02  03 (sum) (FNR%)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   01 setosa      50   0   0    50      0</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   02 versicolor   1   0  49    50    100</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   03 virginica    0   0  50    50      0</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   (sum)          51   0  99   150     33</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Simpler interface, but more memory-effective</span></span></span>
<span class="r-in"><span><span class="va">iris_lda5</span> <span class="op">&lt;-</span> <span class="fu">ml_lda</span><span class="op">(</span>train <span class="op">=</span> <span class="va">iris</span><span class="op">[</span>, <span class="op">-</span><span class="fl">5</span><span class="op">]</span>, response <span class="op">=</span> <span class="va">iris</span><span class="op">$</span><span class="va">Species</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">iris_lda5</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> A mlearning object of class mlLda (linear discriminant analysis):</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Initial call: mlLda.default(train = iris[, -5], response = iris$Species)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Call:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lda(sapply(train, as.numeric), grouping = response)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Prior probabilities of groups:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>     setosa versicolor  virginica </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  0.3333333  0.3333333  0.3333333 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Group means:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>            Sepal.Length Sepal.Width Petal.Length Petal.Width</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> setosa            5.006       3.428        1.462       0.246</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> versicolor        5.936       2.770        4.260       1.326</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> virginica         6.588       2.974        5.552       2.026</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Coefficients of linear discriminants:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>                     LD1         LD2</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Sepal.Length  0.8293776 -0.02410215</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Sepal.Width   1.5344731 -2.16452123</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Petal.Length -2.2012117  0.93192121</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Petal.Width  -2.8104603 -2.83918785</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Proportion of trace:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>    LD1    LD2 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 0.9912 0.0088 </span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside></div>


    <footer><!-- footer --><!--<footer class="bg-secondary">--><div class="bg-secondary full-width">
    <div class="py-100 border-bottom" style="border-color: #454547 !important">
        <div class="container">
            <div class="row">
                <div class="col-lg-4 col-md-4">
                    <div class="mb-5 mb-md-0 text-center text-md-left">
                        <!-- logo -->
                        <img class="mb-30" src="https://www.sciviews.org/images/logo-footer.png" alt="logo"><p class="text-white mb-30"> We build software for reproducible research with R</p>
                        <!-- social icon -->
                        <ul class="list-inline"><li class="list-inline-item">
                                <a class="external-link social-icon-outline" href="https://github.com/SciViews">
                                    <i class="ti-github"></i>
                                </a>
                            </li>

                            <li class="list-inline-item">
                                <a class="external-link social-icon-outline" href="https://twitter.com/PhilGrosjean">
                                    <i class="ti-twitter-alt"></i>
                                </a>
                            </li>

                            <li class="list-inline-item">
                                <a class="external-link social-icon-outline" href="https://www.linkedin.com/in/philippe-grosjean-5b6b29a2/">
                                    <i class="ti-linkedin"></i>
                                </a>
                            </li>

                        </ul></div>
                </div>
                <!-- footer links -->
                <div class="col-lg-2 col-md-4 col-6">
                    <p class="h4 text-white mb-4">Related</p>
                    <ul class="footer-links"><li>
                            <a href="http://econum.umons.ac.be" class="external-link">Our Lab</a>
                        </li>

                        <li>
                            <a href="https://web.umons.ac.be/fs/en/" class="external-link">Our Faculty</a>
                        </li>

                        <li>
                            <a href="https://web.umons.ac.be/complexys/en/" class="external-link">Complexys</a>
                        </li>

                        <li>
                            <a href="https://web.umons.ac.be/infortech/en/" class="external-link">InforTech</a>
                        </li>

                        <li>
                            <a href="https://web.umons.ac.be/en/" class="external-link">UMONS</a>
                        </li>

                    </ul></div>
                <!-- footer links -->
                <div class="col-lg-2 col-md-4 col-6">
                    <p class="h4 text-white mb-4">Quick Link</p>
                    <ul class="footer-links"><li>
                            <a href="https://www.sciviews.org/software/svbox" class="external-link">SciViews Box</a>
                        </li>

                        <li>
                            <a href="https://www.sciviews.org/software/sciviews-r" class="external-link">SciViews::R</a>
                        </li>

                        <li>
                            <a href="https://www.sciviews.org/software/zooimage" class="external-link">Zoo/PhytoImage</a>
                        </li>

                        <li>
                            <a href="https://www.sciviews.org/blog" class="external-link">Blog</a>
                        </li>

                        <li>
                            <a href="https://www.sciviews.org/about" class="external-link">About</a>
                        </li>

                    </ul></div>
                <!-- subscribe form -->
                <div class="col-lg-3 col-md-12 offset-lg-1">
                    <div class="mt-5 mt-lg-0 text-center text-md-left">
                             <p class="h4 mb-4 text-white">Contact Us</p>
                             <p class="text-white mb-4">Need more info?<br><a href="mailto:info@sciviews.org"><span class="text-primary">Leave us a mail...</span></a></p>

                    </div>
                </div>
            </div>
        </div>
    </div>
    <!-- copyright -->
    <div class="pt-4 pb-3 position-relative">
        <div class="container">
            <div class="row">
                <div class="col-lg-6 col-md-5">
                    <p class="text-white text-center text-md-left">
                        <span class="text-primary">SciViews</span> © All Right Reserved</p>
                </div>
                <div class="col-lg-6 col-md-7">
                    <ul class="list-inline text-center text-md-right"><li class="list-inline-item mx-lg-3 my-lg-0 mx-2 my-2">
                            <a class="external-link font-secondary text-white" href="https://creativecommons.org/licenses/by/4.0/">Site content under CC-BY 4.0 license</a>
                        </li>

                    </ul></div>
            </div>
        </div>
        <!-- back to top -->
        <!--<button class="back-to-top">
            <i class="ti-angle-up"></i>
        </button>-->
    </div>
</div>
<!--</footer>-->
<!-- /footer -->

    </footer></div>

  

  

  </body></html>

